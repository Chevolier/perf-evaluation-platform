# Model Performance Evaluation Platform

A comprehensive platform for model (LLMs, VLMs, etc.) deployment and performance evaluation. Supports 1-click deployment of various models on EC2 using vLLM, SGLang, plus comprehensive performance testing and visualization.

## âœ¨ Features

- **Model Deployment**: Deploy and manage models with real-time status tracking
- **Interactive Playground**: Multi-model comparison with streaming inference
- **Performance Testing**: Stress testing and throughput benchmarking
- **Result Visualization**: Charts and analytics for performance metrics
- **Multimodal Support**: Text, image, and video processing capabilities
- **Enterprise Architecture**: Modular backend with service layer architecture

## ğŸ—ï¸ Architecture

```
â”œâ”€â”€ backend/                    # Modular FastAPI API server
â”‚   â”œâ”€â”€ app.py                  # FastAPI application factory
â”‚   â”œâ”€â”€ api/                    # API layer
â”‚   â”‚   â””â”€â”€ routes/             # Route blueprints
â”‚   â”‚       â”œâ”€â”€ model_routes.py       # Model management & deployment
â”‚   â”‚       â”œâ”€â”€ inference_routes.py   # Inference operations
â”‚   â”‚       â”œâ”€â”€ stress_test_routes.py # Performance testing APIs
â”‚   â”‚       â””â”€â”€ results_routes.py     # Results management & export
â”‚   â”œâ”€â”€ services/               # Business logic layer
â”‚   â”‚   â”œâ”€â”€ model_service.py          # Model deployment & status
â”‚   â”‚   â”œâ”€â”€ inference_service.py      # Multi-model inference
â”‚   â”‚   â””â”€â”€ stress_test_service.py    # Stress testing orchestration
â”‚   â”œâ”€â”€ core/                   # Core functionality
â”‚   â”‚   â”œâ”€â”€ models/             # Model definitions & registry
â”‚   â”‚   â”‚   â”œâ”€â”€ model_registry.py     # Model configuration registry
â”‚   â”‚   â”‚   â””â”€â”€ bedrock_models.py     # Bedrock model definitions
â”‚   â”‚   â””â”€â”€ clients/            # API clients
â”‚   â”œâ”€â”€ config/                 # Configuration management
â”‚   â”‚   â”œâ”€â”€ config_manager.py         # Config loading & management
â”‚   â”‚   â”œâ”€â”€ settings.py               # Application settings
â”‚   â”‚   â””â”€â”€ environments/             # Environment-specific configs
â”‚   â”œâ”€â”€ utils/                  # Utilities
â”‚   â”‚   â”œâ”€â”€ logging_config.py         # Logging configuration
â”‚   â”‚   â”œâ”€â”€ storage.py                # File storage utilities
â”‚   â”‚   â”œâ”€â”€ helpers.py                # General helpers
â”‚   â”‚   â””â”€â”€ image_processing.py       # Image processing utils
â”‚   â”œâ”€â”€ evalscope/              # Evaluation framework integration
â”‚   â””â”€â”€ data/                   # Backend data storage
â”œâ”€â”€ frontend/                   # React web application
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ pages/              # Main application pages
â”‚       â”‚   â”œâ”€â”€ ModelHubPage.jsx      # Model deployment interface
â”‚       â”‚   â”œâ”€â”€ PlaygroundPage.jsx    # Interactive inference testing
â”‚       â”‚   â”œâ”€â”€ StressTestPage.jsx    # Performance stress testing
â”‚       â”‚   â””â”€â”€ VisualizationPage.jsx # Results visualization
â”‚       â”œâ”€â”€ components/         # Reusable UI components
â”‚       â”‚   â”œâ”€â”€ PlaygroundModelSelector.jsx  # Model selection UI
â”‚       â”‚   â”œâ”€â”€ PlaygroundResultsDisplay.jsx # Results display
â”‚       â”‚   â”œâ”€â”€ ModelSelector.jsx            # Generic model selector
â”‚       â”‚   â””â”€â”€ ...                          # Other components
â”‚       â””â”€â”€ App.js              # Main application shell & routing
â”œâ”€â”€ outputs/                    # Test results & session data
â”œâ”€â”€ data/                       # Datasets & data files
â”œâ”€â”€ tests/                      # Test suites
â”œâ”€â”€ docs/                       # Documentation & images
â”œâ”€â”€ setup.sh                    # Environment setup script
â”œâ”€â”€ start.sh                    # Application start script
â””â”€â”€ requirements.txt            # Root Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+ (Required)
- Node.js 16+ 
- AWS credentials configured

Recommended instance g5.2xlarge.

### Automated Setup (Recommended)

```bash
# Run the setup script 
./start.sh
```

If the environments are not configured, it will automatically install backend and frontend packages, then start the service. If the environments are already setup, it will directly start the service.

If you need to update the environments, you can run setup first `./setup.sh`, then run `./start.sh`

### Manual Setup

**1. Backend Environment**

```bash
# Create Python environment
cd backend

uv venv --python 3.10
source .venv/bin/activate
uv pip install --upgrade pip
uv pip install -r requirements.txt

# Configure AWS credentials
aws configure
# OR set environment variables:
export AWS_ACCESS_KEY_ID=your_key
export AWS_SECRET_ACCESS_KEY=your_secret
export AWS_SESSION_TOKEN=your_token  # if using temporary credentials
```

**2. Frontend Environment**

First, please install node js using the following commands in Linux. In other systems, please follow https://nodejs.org/en/download/ to install.

```bash
# Download and install nvm:
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.3/install.sh | bash

# in lieu of restarting the shell
\. "$HOME/.nvm/nvm.sh"

# Download and install Node.js:
nvm install 24

# Verify the Node.js version:
node -v # Should print "v24.11.1".

# Verify npm version:
npm -v # Should print "11.6.2".
```

```bash
# Install Node.js dependencies
cd frontend
npm install
```

**3. Start the Platform**

```bash
# Terminal 1: Start backend (from project root)
python run_backend.py

# Terminal 2: Start frontend (from project root)
cd frontend && npm start
```

**4. Access the Application**

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:5000
- **Health Check**: http://localhost:5000/health


## ğŸ“– Platform Overview

### Core Modules

**1. Model Deployment (æ¨¡å‹éƒ¨ç½²)**
- Deploy models to AWS infrastructure (EC2)
- Support for multiple instance types (g5.xlarge, g6e.xlarge, etc.) and inference engines (vllm, sglang)
- Real-time deployment status monitoring

<img src="docs/images/Deployment.png" 
     alt="Model Deployment (æ¨¡å‹éƒ¨ç½²)" 
     width="800">

**2. Interactive Playground (åœ¨çº¿ä½“éªŒ)**
- Test the connectivity to the deployed model
- Multimodal input support (text, images)
- Real-time response generation (to come)

<img src="docs/images/Playground.png" 
     alt="Plaground (åœ¨çº¿ä½“éªŒ)" 
     width="800">

**3. Performance Testing (æ€§èƒ½è¯„æµ‹)**
- Stress testing with configurable parameters
- Support random/random_vl datasets, some open datasets and custom dataset, for custom dataset, prepare it using jsonl format with each line having at least the prompt keyword: {"prompt": "Tell me a joke."}
- Throughput and latency benchmarking
- Concurrent request simulation
- Performance metrics collection

<img src="docs/images/StressTest.png" 
     alt="Stress Test (æ€§èƒ½è¯„æµ‹)" 
     width="800">

**4. Result Visualization (ç»“æœå±•ç¤º)**
- Performance charts and analytics
- Model comparison dashboards
- Historical trend analysis
- Export capabilities

<img src="docs/images/Visualization.png" 
     alt="Visualization (ç»“æœå±•ç¤º)" 
     width="800">

### System Requirements

1. To deploy an model in the same instance, then select the appropriate EC2 instance based on the model, for instance, to deploy Qwen3-8B, select an instance with GPU memory >= 24 GB, like g5.xlarge.

2. If only use the platform for test, models are deployed elsewhere, then the following requirements are enough, e.g., m5.2xlarge.

- **Minimum**: 8GB RAM, 4 CPU cores
- **Recommended**: 16GB RAM, 8 CPU cores
- **Storage**: 50GB free space for model deployments
- **Network**: Stable internet for AWS API calls

## TODOs
- [ ] Streaming Output in Playground Page
- [ ] Support of SageMaker Endpoint VLM models
- [ ] Support of evaluations of LLM/VLM models on various benchmarks

## ğŸ”’ Security Best Practices

- Store AWS credentials in environment variables or AWS credentials file
- Use IAM roles with minimum required permissions
- Enable VPC security groups for deployed models
- Implement rate limiting for production deployments
- Regular security updates for all dependencies

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Follow the existing code style and architecture patterns
4. Add tests for new functionality
5. Ensure all tests pass (`python tests/test_new_system.py`)
6. Submit a pull request with detailed description

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“ Support

**For Technical Issues:**
- Check the troubleshooting section above
- Review logs in `logs/backend.log`, `logs/frontend.log`, `backend/logs/development.log`
- Test system health with provided test scripts

**For Feature Requests:**
- Open an issue with detailed requirements
- Include use cases and expected behavior

---

**ğŸš€ Built for enterprise-scale model performance evaluation and deployment**